{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3:  Filtered Vocabulary\n",
    "\n",
    "* Janghyuk Boo 40008835 <br/>\n",
    "* Jixuan Li    40073785"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import  word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import csv\n",
    "\n",
    "data = pd.read_csv (\"covid_training.tsv\", sep = '\\t')\n",
    "extracted=data[['text','q1_label']]\n",
    "# stopWords = nltk.corpus.stopwords.words('english')\n",
    "def preprocess(text): \n",
    "    tokenized = nltk.word_tokenize(text.lower())\n",
    "#     removedStopWords = [w for w in tokenized if w not in stopWords]\n",
    "#     punctual_removed = [w for w in removedStopWords if w.isalpha()]\n",
    "    punctual_removed = [w for w in tokenized if w.isalpha()]\n",
    "    return punctual_removed\n",
    "\n",
    "lower= extracted['text'].apply(lambda text: preprocess(text))\n",
    "def convert_tuple_str(tup):\n",
    "  return ' '.join(tup)\n",
    "def convert_tuple_str2(tup):\n",
    "    lists=list()\n",
    "    for i in tup:\n",
    "        a=' '.join(i)\n",
    "        lists.append(a)\n",
    "    return lists\n",
    "\n",
    "strings= lower.apply(lambda row: convert_tuple_str(row) )\n",
    "out = ' '.join(strings).split(' ')\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "d=defaultdict(int)\n",
    "for lister in lower:\n",
    "    for item in lister:\n",
    "        d[item]+=1\n",
    "        \n",
    "#remove first occurance\n",
    "tokens=[key for key,value in d.items() if value>1]\n",
    "texts = [[word for word in document if word in tokens] for document in lower]\n",
    "out=convert_tuple_str2(texts)\n",
    "out= ' '.join(out).split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1091"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "f_dist1 =FreqDist(out)\n",
    "vocab=dict(f_dist1)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    247\n",
      "0    152\n",
      "Name: q1_label, dtype: int64\n",
      "FV vocab size 1091\n"
     ]
    }
   ],
   "source": [
    "smooth=0.01\n",
    "yes = {}\n",
    "no = {}\n",
    "factual_count=0\n",
    "not_factual_count=0\n",
    "\n",
    "for term in vocab:\n",
    "    yes[term] = smooth\n",
    "    no[term] = smooth\n",
    "    \n",
    "condition_yes = {}\n",
    "condition_no = {}\n",
    "\n",
    "digit=extracted['q1_label'].map(dict(yes=1, no=0))\n",
    "print(digit.value_counts())\n",
    "num_yes=digit.value_counts()[1]\n",
    "num_no=digit.value_counts()[0]\n",
    "tweet_count=num_yes+num_no\n",
    "def counting(text,target):\n",
    "    if target ==1:\n",
    "        dic= yes\n",
    "    else:\n",
    "        dic= no\n",
    "    for token in text.split(' '):\n",
    "        if token in dic:\n",
    "            dic[token]+=1\n",
    "    \n",
    "with open(\"covid_training.tsv\", encoding=\"utf8\") as file:\n",
    "    is_first_line = True\n",
    "    reader = csv.reader(file, delimiter='\\t')\n",
    "\n",
    "    for row in reader:\n",
    "        if is_first_line:\n",
    "            is_first_line = False\n",
    "            continue\n",
    "        fact = 0\n",
    "        if row[2].lower() == 'yes':\n",
    "            fact = 1\n",
    "        else:\n",
    "            fact = 0\n",
    "        \n",
    "        tweet_text = row[1].lower()\n",
    "        counting(tweet_text, fact)\n",
    "    prob_is_factual = np.log10(num_yes / tweet_count)\n",
    "    prob_is_not_factual = np.log10(num_no / tweet_count)\n",
    "\n",
    "    for term in yes:\n",
    "        condition_yes[term] = np.log10(yes[term] / (num_yes + (len(vocab) * smooth)) )#smoothed_yes\n",
    "    for term in no:\n",
    "        condition_no[term] = np.log10(no[term] / (num_no + (len(vocab) * smooth)))#smoothed_no\n",
    "\n",
    "print(\"FV vocab size\",len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_result = {}\n",
    "correct_counter = 0\n",
    "with open(\"covid_test_public.tsv\", encoding='utf8') as f:\n",
    "    test_set = csv.reader(f, delimiter='\\t')\n",
    "    for line in test_set:\n",
    "        test_tweet_id = line[0]\n",
    "        test_tweet_text = preprocess(line[1])\n",
    "        test_tweet_target = line[2]\n",
    "        yes_score = prob_is_factual\n",
    "        no_score = prob_is_not_factual\n",
    "        for token in test_tweet_text:\n",
    "            cur_token = token\n",
    "            if cur_token in condition_yes:\n",
    "                yes_score += condition_yes[cur_token]\n",
    "                no_score += condition_no[cur_token]\n",
    "            else:\n",
    "                yes_score += np.log10(0.01/(num_yes + (len(vocab) * smooth)))\n",
    "                no_score += np.log10(0.01/(num_no + (len(vocab) * smooth)))\n",
    "        prediction = 'no'\n",
    "        final_score = no_score\n",
    "        if yes_score>= no_score:\n",
    "            prediction = 'yes'\n",
    "            final_score = yes_score\n",
    "        correctness = 'wrong'\n",
    "        if test_tweet_target == prediction:\n",
    "            correctness = 'correct'\n",
    "            correct_counter+=1\n",
    "        innerString = test_tweet_id+ \"  \" + prediction + \"  \" + str(final_score) + \"  \"+test_tweet_target+\"  \"+ correctness\n",
    "        test_result[test_tweet_id] = innerString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('./trace_NB-BOW-FV.txt', 'w') as f:\n",
    "    for content in test_result.values():\n",
    "        f.write(content)\n",
    "        f.write('\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_count=0\n",
    "incorrect_count=0\n",
    "predicted_count=0\n",
    "predicted_wrong_count=0\n",
    "total_factual=0\n",
    "total_not_factual=0\n",
    "\n",
    "count=0\n",
    "\n",
    "with open(\"trace_NB-BOW-FV.txt\", encoding='utf8') as f:\n",
    "    test_set = csv.reader(f, delimiter=' ')\n",
    "    for line in test_set:\n",
    "        prediction=line[2]\n",
    "        answer=line[6]\n",
    "        correct=line[8]\n",
    "        if correct=='correct':\n",
    "            if answer == \"yes\":\n",
    "                correct_count += 1\n",
    "            else:\n",
    "                incorrect_count += 1\n",
    "\n",
    "        if prediction == \"yes\":\n",
    "            predicted_count += 1\n",
    "        else:\n",
    "            predicted_wrong_count += 1\n",
    "        if answer == \"yes\":\n",
    "            total_factual += 1\n",
    "        else:\n",
    "            total_not_factual += 1\n",
    "\n",
    "        count+=1\n",
    "\n",
    "accuracy = (correct_count + incorrect_count) / count\n",
    "\n",
    "precision_fact = correct_count / predicted_count\n",
    "precision_not_fact = incorrect_count / predicted_wrong_count\n",
    "recall_fact = correct_count / total_factual\n",
    "recall_not_fact = incorrect_count / total_not_factual\n",
    "beta = 1\n",
    "f1_fact = ((beta**2 + 1) * precision_fact * recall_fact) / \\\n",
    "                 ((beta**2 * precision_fact) + recall_fact)\n",
    "f1_not_fact = ((beta**2 + 1) * precision_not_fact * recall_not_fact) / \\\n",
    "                     ((beta**2 * precision_not_fact) + recall_not_fact)\n",
    "\n",
    "line_to_write = \"{:.4}\".format(accuracy) + \"\\r\"\n",
    "line_to_write += \"{:.4}\".format(precision_fact) + \"  \" + \"{:.4}\".format(precision_not_fact) + \"\\r\"\n",
    "line_to_write += \"{:.4}\".format(recall_fact) + \"  \" + \"{:.4}\".format(recall_not_fact) + \"\\r\"\n",
    "line_to_write += \"{:.4}\".format(f1_fact) + \"  \" + \"{:.4}\".format(f1_not_fact) + \"\\r\"\n",
    "\n",
    "    # Write the line to the output file\n",
    "f = open(\"eval_NB-BOW-FV.txt\", \"a\")\n",
    "f.write(line_to_write)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
